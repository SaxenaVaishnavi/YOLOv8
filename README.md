# YOLOv8 Object Detection Model Implementation

This repository contains the implementation of the YOLOv8 model for real-time object detection purposes, developed as part of an internship project.

## Overview

The YOLOv8 model is a state-of-the-art deep learning model known for its efficiency in real-time object detection. This implementation aims to provide a robust solution for detecting objects in live video streams using pre-trained weights.

## Features

- Real-time object detection using YOLOv8.
- Integration with webcam for live video analysis.
- Implementation of bounding boxes for identified objects.

## Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/SaxenaVaishnavi/YOLOv8.git
   cd your-repo
2. Install dependencies:
   Ensure you have Python 3.6 or later installed.
   ```bash
   pip install -r requirements.txt
3. Activate the virtual environment (if using):
   ```bash
   conda activate yolo_project  # or .\yolo_project\Scripts\activate for venv
4. Run the YOLOv8 model on your webcam:
   Replace my_code.py with your script name.
   ```bash
   python my_code.py

## Test Data and Outputs
- The test video files being large in size could not be uploaded directly on GitHub.
- Download the test data and outputs from the provided Google Drive links to replicate the results.
- These videos were scraped from the net for general inference purposes and the model would work the same way on any other data too.

- **Test Data:** The test videos used for evaluation can be found [here](https://drive.google.com/drive/folders/1wpQIwz3vM20okamig8uqatKdrDKw7iZX?usp=sharing).
- **Outputs:** Results and outputs generated from the model can be viewed [here](https://drive.google.com/drive/folders/1374JvZXtmfxYWyXYImFUD96uWHEiFHgc?usp=sharing).


## License
This project is licensed under the MIT License. See the LICENSE file for details.
   
